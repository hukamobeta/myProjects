{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft_XBW61Us5T"
      },
      "source": [
        "# Работа со строковыми значениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6J7U-e0Us5V"
      },
      "source": [
        "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
        "\n",
        "Материалы:\n",
        "* Макрушин С.В. Лекция \"Работа со строковыми значениям\"\n",
        "* https://pyformat.info/\n",
        "* https://docs.python.org/3/library/re.html\n",
        "    * https://docs.python.org/3/library/re.html#flags\n",
        "    * https://docs.python.org/3/library/re.html#functions\n",
        "* https://pythonru.com/primery/primery-primeneniya-regulyarnyh-vyrazheniy-v-python\n",
        "* https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
        "* https://realpython.com/nltk-nlp-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q97OGr9sUs5V"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cdiHV7dUs5W"
      },
      "source": [
        "\n",
        "1. Вывести на экран данные из словаря `obj` построчно в виде `k = v`, задав формат таким образом, чтобы знак равенства оказался на одной и той же позиции во всех строках. Строковые литералы обернуть в кавычки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hYOk6xWwUs5W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize.toktok import ToktokTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM1L4t2gVH_h",
        "outputId": "bc63e562-7bf5-493a-f67e-32edf13707a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnPvdC9VUs5X",
        "outputId": "0fd682dd-bb6c-4c30-d0a3-5d6184331e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhFf40pGUs5X"
      },
      "outputs": [],
      "source": [
        "obj = {\n",
        "    \"home_page\": \"https://github.com/pypa/sampleproject\",\n",
        "    \"keywords\": \"sample setuptools development\",\n",
        "    \"license\": \"MIT\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3OcVYk6Us5Y",
        "outputId": "0eeb4634-53a4-4160-a775-0c37cd780628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "home_page  = \"https://github.com/pypa/sampleproject\"\n",
            "keywords   = \"sample setuptools development\"\n",
            "license    = \"MIT\"\n"
          ]
        }
      ],
      "source": [
        "for k, v in obj.items():\n",
        "    print(f'{k:10} = \"{v}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dug2cicjUs5Y"
      },
      "source": [
        "2. Написать регулярное выражение,которое позволит найти номера групп студентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwDvAXSlUs5Y",
        "outputId": "52e0e6a6-9f5e-4927-c97a-4857de491b0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Евгения гр.ПМ19-1\n",
              "1         Илья пм 20-4\n",
              "2            Анна 20-3\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "obj = pd.Series([\"Евгения гр.ПМ19-1\", \"Илья пм 20-4\", \"Анна 20-3\"])\n",
        "obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b-38vfHUs5Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMHkedDPUs5Y",
        "outputId": "2e621bb1-437e-4079-ae0f-c3b0c302cb65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19-1\n",
            "20-4\n",
            "20-3\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "students = [\"евгенияпм19-1\", \"ильяпм20-4\", \"анна20-3\"]\n",
        "for student in students:\n",
        "    match = re.search(r'\\d{2}-\\d+', student)\n",
        "    if match:\n",
        "        print(match.group(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr3bmEMBUs5Y"
      },
      "source": [
        "3. Разбейте текст формулировки задачи 2 на слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkHGBGk9Us5Y"
      },
      "outputs": [],
      "source": [
        "s = 'Написать регулярное выражение , которое позволит найти номера групп студентов.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnV1NkvYUs5Y",
        "outputId": "147e99a0-8737-4e84-d057-a6b330108ed5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Написать',\n",
              " 'регулярное',\n",
              " 'выражение',\n",
              " 'которое',\n",
              " 'позволит',\n",
              " 'найти',\n",
              " 'номера',\n",
              " 'групп',\n",
              " 'студентов']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "temp = []\n",
        "for el in nltk.word_tokenize(s):\n",
        "    if len(el) != 1:\n",
        "        temp.append(el)\n",
        "temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JPJxPg-Us5Z"
      },
      "source": [
        "## Лабораторная работа 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH5hQV3DUs5Z"
      },
      "source": [
        "### Форматирование строк"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKfulBMRUs5Z"
      },
      "source": [
        "1\\. Загрузите данные из файла `recipes_sample.csv` (__ЛР2__) в виде `pd.DataFrame` `recipes` При помощи форматирования строк выведите информацию об id рецепта и времени выполнения 5 случайных рецептов в виде таблицы следующего вида:\n",
        "\n",
        "    \n",
        "    |      id      |  minutes  |\n",
        "    |--------------------------|\n",
        "    |    61178     |    65     |\n",
        "    |    202352    |    80     |\n",
        "    |    364322    |    150    |\n",
        "    |    26177     |    20     |\n",
        "    |    224785    |    35     |\n",
        "    \n",
        "Обратите внимание, что ширина столбцов заранее неизвестна и должна рассчитываться динамически, в зависимости от тех данных, которые были выбраны. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('recipes_sample.csv')\n",
        "df_5 = df.sample(5)\n",
        "df_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "-g9-M3VqCs84",
        "outputId": "65906abb-a8f1-40a2-9f7c-a0dbb2245e4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    name      id  minutes  \\\n",
              "28581         vegan chili casserole with polenta topping  221188       70   \n",
              "28871                                   vienna breakfast  140069       20   \n",
              "12624  greek style roasted chicken legs  potatoes and...  143504       90   \n",
              "6825                                 chocolate oats bars   19783       60   \n",
              "3779       british style cheese and onion sandwich for 2  417292       10   \n",
              "\n",
              "       contributor_id   submitted  n_steps  \\\n",
              "28581          321390  2007-04-07      9.0   \n",
              "28871           35526  2005-10-04      4.0   \n",
              "12624           89831  2005-11-01      8.0   \n",
              "6825            27411  2002-02-15      NaN   \n",
              "3779            47892  2010-03-21      6.0   \n",
              "\n",
              "                                             description  n_ingredients  \n",
              "28581  fresh polenta tops off this hearty, heart-heal...           14.0  \n",
              "28871  i used to have a secretary that would bring th...            2.0  \n",
              "12624  if you love greek food as much as we do then y...           11.0  \n",
              "6825                                                 NaN            NaN  \n",
              "3779   about a week ago i found a really good quality...            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b467742d-a194-4e77-9ce4-9ae0357a98f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>description</th>\n",
              "      <th>n_ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28581</th>\n",
              "      <td>vegan chili casserole with polenta topping</td>\n",
              "      <td>221188</td>\n",
              "      <td>70</td>\n",
              "      <td>321390</td>\n",
              "      <td>2007-04-07</td>\n",
              "      <td>9.0</td>\n",
              "      <td>fresh polenta tops off this hearty, heart-heal...</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28871</th>\n",
              "      <td>vienna breakfast</td>\n",
              "      <td>140069</td>\n",
              "      <td>20</td>\n",
              "      <td>35526</td>\n",
              "      <td>2005-10-04</td>\n",
              "      <td>4.0</td>\n",
              "      <td>i used to have a secretary that would bring th...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12624</th>\n",
              "      <td>greek style roasted chicken legs  potatoes and...</td>\n",
              "      <td>143504</td>\n",
              "      <td>90</td>\n",
              "      <td>89831</td>\n",
              "      <td>2005-11-01</td>\n",
              "      <td>8.0</td>\n",
              "      <td>if you love greek food as much as we do then y...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6825</th>\n",
              "      <td>chocolate oats bars</td>\n",
              "      <td>19783</td>\n",
              "      <td>60</td>\n",
              "      <td>27411</td>\n",
              "      <td>2002-02-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3779</th>\n",
              "      <td>british style cheese and onion sandwich for 2</td>\n",
              "      <td>417292</td>\n",
              "      <td>10</td>\n",
              "      <td>47892</td>\n",
              "      <td>2010-03-21</td>\n",
              "      <td>6.0</td>\n",
              "      <td>about a week ago i found a really good quality...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b467742d-a194-4e77-9ce4-9ae0357a98f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b467742d-a194-4e77-9ce4-9ae0357a98f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b467742d-a194-4e77-9ce4-9ae0357a98f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_id = max(df_5['id'].astype(str).apply(len))\n",
        "max_len_minutes = max(df_5['minutes'].astype(str).apply(len))\n",
        "\n",
        "id = 'id'\n",
        "minutes = 'minutes'\n",
        "\n",
        "print(f'|{id:^{max_len_id + 8}}|{minutes:^{max_len_minutes + 8}}|')\n",
        "print('|' + '-'*(16 + len(id) + len(minutes))+ '|')\n",
        "\n",
        "for index, row in df_5.iterrows():\n",
        "  id = row['id']\n",
        "  minutes = row['minutes']\n",
        "  print(f'|{id:^{max_len_id + 8}}|{minutes:^{max_len_minutes + 8}}|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU0ZwWHdDtaU",
        "outputId": "31325806-b182-4e55-e511-f2abefd435be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|      id      | minutes  |\n",
            "|-------------------------|\n",
            "|    221188    |    70    |\n",
            "|    140069    |    20    |\n",
            "|    143504    |    90    |\n",
            "|    19783     |    60    |\n",
            "|    417292    |    10    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-fBAPBvUs5Z"
      },
      "source": [
        "2\\. Напишите функцию `show_info`, которая по данным о рецепте создает строку (в смысле объекта python) с описанием следующего вида:\n",
        "\n",
        "```\n",
        "\"Название Из Нескольких Слов\"\n",
        "\n",
        "1. Шаг 1\n",
        "2. Шаг 2\n",
        "----------\n",
        "Автор: contributor_id\n",
        "Среднее время приготовления: minutes минут\n",
        "```\n",
        "\n",
        "    \n",
        "Данные для создания строки получите из файлов `recipes_sample.csv` (__ЛР2__) и `steps_sample.xml` (__ЛР3__). \n",
        "Вызовите данную функцию для рецепта с id `170895` и выведите (через `print`) полученную строку на экран."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('steps_sample.xml') as f:\n",
        "  bs = BeautifulSoup(f, 'xml')\n",
        "\n",
        "steps_dict = {}\n",
        "\n",
        "for recipe in bs.find_all('recipe'):\n",
        "  recipe_id = int(recipe.id.text)\n",
        "  steps = [step.text for step in recipe.find_all('step')]\n",
        "  steps_dict[recipe_id] = steps\n",
        "\n",
        "row = df[df['id'] == 170895]\n",
        "\n",
        "name = row['name'].iloc[0]\n",
        "minutes = row['minutes'].iloc[0]\n",
        "author_id = row['contributor_id'].iloc[0]\n",
        "steps = steps_dict[170895]"
      ],
      "metadata": {
        "id": "B56GopI8D6UW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_info(name: str, steps: list, minutes: int, author_id: int) -> str:\n",
        "  s = f'\"{name.title()}\"\\n\\n'\n",
        "\n",
        "  for index, step in enumerate(steps):\n",
        "    s += f'{index+1}. {step.capitalize()}\\n'\n",
        "  s += '-' * 10 + '\\n'\n",
        "  s += f'Автор: {author_id}\\n'\n",
        "  s += f'Среднее время приготовления: {minutes} минут\\n'\n",
        "  return s"
      ],
      "metadata": {
        "id": "i8S6n8jEEje6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hNdF-Ew7Us5Z"
      },
      "outputs": [],
      "source": [
        "assert (\n",
        "    show_info(\n",
        "        name=\"george s at the cove black bean soup\",\n",
        "        steps=[\n",
        "            \"clean the leeks and discard the dark green portions\",\n",
        "            \"cut the leeks lengthwise then into one-inch pieces\",\n",
        "            \"melt the butter in a medium skillet , med\",\n",
        "        ],\n",
        "        minutes=90,\n",
        "        author_id=35193,\n",
        "    )\n",
        "    == '\"George S At The Cove Black Bean Soup\"\\n\\n1. Clean the leeks and discard the dark green portions\\n2. Cut the leeks lengthwise then into one-inch pieces\\n3. Melt the butter in a medium skillet , med\\n----------\\nАвтор: 35193\\nСреднее время приготовления: 90 минут\\n'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LZ1YIePUs5Z"
      },
      "source": [
        "## Работа с регулярными выражениями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21gxTG8bUs5Z"
      },
      "source": [
        "3\\. Напишите регулярное выражение, которое ищет следующий паттерн в строке: число (1 цифра или более), затем пробел, затем слова: hour или hours или minute или minutes. Произведите поиск по данному регулярному выражению в каждом шаге рецепта с id 25082. Выведите на экран все непустые результаты, найденные по данному шаблону."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "for index, step in enumerate(steps_dict[25082]):\n",
        "  res = re.findall(r\"[1-9][0-9]+ hour[s]?|[1-9][0-9]+ minute[s]?\", step)\n",
        "  if len(res) != 0 :\n",
        "    print(f'Шаг {index+1}: {res}')"
      ],
      "metadata": {
        "id": "nRwRXgqnVlsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb69aa7-c0b7-41b6-ed90-51ed1773b480"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Шаг 6: ['20 minutes']\n",
            "Шаг 8: ['10 minutes']\n",
            "Шаг 14: ['10 minutes']\n",
            "Шаг 17: ['20 minutes', '30 minutes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-phr30wUs5Z"
      },
      "source": [
        "4\\. Напишите регулярное выражение, которое ищет шаблон вида \"this..., but\" _в начале строки_ . Между словом \"this\" и частью \", but\" может находиться произвольное число букв, цифр, знаков подчеркивания и пробелов. Никаких других символов вместо многоточия быть не может. Пробел между запятой и словом \"but\" может присутствовать или отсутствовать.\n",
        "\n",
        "Используя строковые методы `pd.Series`, выясните, для каких рецептов данный шаблон содержится в тексте описания. Выведите на экран количество таких рецептов и 3 примера подходящих описаний (текст описания должен быть виден на экране полностью)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'].isna().sum()\n",
        "df['description'].fillna(' ', inplace=True)\n",
        "df_4 = df[df['description'].str.contains('^this[\\w\\d\\s]+,[ ]?but', regex=True)]\n",
        "print('Количество подходящих описаний:', df_4.shape[0])\n",
        "pd.set_option('max_colwidth', int(df_4['description'].apply(len).max() + 10))\n",
        "df_4['description'].sample(3)"
      ],
      "metadata": {
        "id": "5saD2Vi9VmMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da118c9f-5b33-445b-8c52-25b07bb8830b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество подходящих описаний: 134\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19431                                                                                                                                                                                                              this is an easy cake, but taste so devine. be prepared to be very popular where ever you take it. it is pretty so it looks like you worked a lot harder on it than you really have to. yummy!!\n",
              "20844                                                                                                                                                                                                               this cake is easier to make the the traditional recipe, but has that same delicious taste. i usually have all the ingredients on hand and can make this when the kids come over unexpectedly.\n",
              "5779     this is a bit time consuming, but i thought it was worth it! there's not really any chopping so that saves time. it's not as hard as it looks to make. we all loved this, even the kids. i prepared this in my electric skillet. prep and cook times are approximate. note: to fricasse a broiler-fryer chicken, select 3-4 pound broiler-fryer chicken and cook slowly 45 minutes or until fork-tender.\n",
              "Name: description, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28BRisEUs5a"
      },
      "source": [
        "5\\. В текстах шагов рецептов обыкновенные дроби имеют вид \"a / b\". Используя регулярные выражения, уберите в тексте шагов рецепта с id 72367 пробелы до и после символа дроби. Выведите на экран шаги этого рецепта после их изменения."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('steps_sample.xml') as f:\n",
        "  data = BeautifulSoup(f, 'xml')\n",
        "\n",
        "steps_dict = {}\n",
        "\n",
        "for recipe in data.find_all('recipe'):\n",
        "  recipe_id = int(recipe.id.text)\n",
        "  steps_dict[recipe_id] = [step.text for step in recipe.find_all('step')]\n",
        "\n",
        "for step in steps_dict[72367]:\n",
        "  print(re.sub(r'\\d+ / \\d+', '\\1/\\2', step, count=0))"
      ],
      "metadata": {
        "id": "TPPXsYp_Vmzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56dbea3a-20ca-4fe5-c767-328e08c5c921"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mix butter , flour , \u0001/\u0002 c\n",
            "sugar and 1-\u0001/\u0002 t\n",
            "vanilla\n",
            "press into greased 9\" springform pan\n",
            "mix cream cheese , \u0001/\u0002 c\n",
            "sugar , eggs and \u0001/\u0002 t\n",
            "vanilla beating until fluffy\n",
            "pour over dough\n",
            "combine apples , \u0001/\u0002 c\n",
            "sugar and cinnamon\n",
            "arrange on top of cream cheese mixture and sprinkle with almonds\n",
            "bake at 350 for 45-55 minutes , or until tester comes out clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRX-VLyeUs5a"
      },
      "source": [
        "### Сегментация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X3wEUc6Us5a"
      },
      "source": [
        "6\\. Разбейте тексты шагов рецептов на слова при помощи пакета `nltk`. Посчитайте и выведите на экран кол-во уникальных слов среди всех рецептов. Словом называется любая последовательность алфавитных символов (для проверки можно воспользоваться `str.isalpha`). При подсчете количества уникальных слов не учитывайте регистр."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = steps_dict.values()\n",
        "flat_arr = [item.lower() for sublist in arr for item in sublist]\n",
        "flat_arr[:3]\n",
        "toktok = ToktokTokenizer()\n",
        "res = toktok.tokenize(flat_arr)\n",
        "print('Количество уникальных слов:', len(set(filter(str.isalpha, res))))"
      ],
      "metadata": {
        "id": "XbX4RuQzVnqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0bac42-2f12-489a-859f-549dd6cd4579"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество уникальных слов: 14953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ucez9YdUs5a"
      },
      "source": [
        "7\\. Разбейте описания рецептов из `recipes` на предложения при помощи пакета `nltk`. Найдите 5 самых длинных описаний (по количеству _предложений_) рецептов в датасете и выведите строки фрейма, соответствующие этим рецептами, в порядке убывания длины."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "df['sentence_count'] = df['description'].apply(lambda x : len(tokenizer.tokenize(x))) \n",
        "df.sort_values('sentence_count', ascending=False).head(5)"
      ],
      "metadata": {
        "id": "ueA0Q1K2VoDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11c513c9-14fa-4bbe-aa47-c4cefda773a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                   name  \\\n",
              "18408                      my favorite buttercream icing for decorating   \n",
              "481           alligator claws  avocado fritters  with chipotle lime dip   \n",
              "22566                                         rich barley mushroom soup   \n",
              "6779                                                      chocolate tea   \n",
              "16296  little bunny foo foo cake  carrot cake  with cream cheese frosti   \n",
              "\n",
              "           id  minutes  contributor_id   submitted  n_steps  \\\n",
              "18408  334113       30          681465  2008-10-30     12.0   \n",
              "481    287008       45          765354  2008-02-19      NaN   \n",
              "22566  328708       60          221776  2008-10-03      NaN   \n",
              "6779   205348        6          428824  2007-01-14      NaN   \n",
              "16296  316000       68          689540  2008-07-27     14.0   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           description  \\\n",
              "18408  this wonderful icing is used for icing cakes and cookies as well as for borders and art work on cakes.  it makes a delicious filling also between the layers of cakes and under fondant icing.  you can make roses but it takes 3 or more days to dry them depending on the humidity. \\r\\n\\r\\nthere are many versions of “buttercream” icing. some are made with eggs and all butter.  some varieties, you have to cook your sugar to a softball stage.  others are 100% shortening or a combination of shortening and butter.\\r\\n\\r\\neach decorator has his or her favorite.  i personally think that the best taste and textured recipe is the one that has you cook your sugar, add to whipped eggs and use pounds of butter per batch. but…. i live in a state that can easily be a 100 degrees for days on end during the summer and you know what butter does on hot days.  it melts! ...   \n",
              "481    a translucent golden-brown crust allows the green of the avocado to be seen.  the crispy exterior is a counterpoint to the unctuous interior.  these are a signature dish for me, and the one i most often get requests to make (although my seafood and ricotta stuffed buckwheat pancakes run a close second).\\r\\n\\r\\nthese fritters came about ten years ago when i was shopping for a dinner i was making for a friend who is a cia-trained chef.  i was in a vegetable market and saw these gorgeous avocados that i just knew would be ripe in the next two days.  i tried to think of what i could do with them since a) everyone serves cold avocado, and b) i really am not fond of guacamole.  as i tried to think of what i could make with them that was hot, the work 'fritters' jumped into my head.  having never made a fritter before, i was a little surprised to have tha...   \n",
              "22566  this is one of the best soups i've ever made and it is even worthy of company.  so simple, yet rich in deep, mushroomy flavor.  the inspiration was zaar #26877, a delicious mushroom rice casserole.  i found i couldn't stop eating the liquid before putting the casserole into the oven and that gave me the idea that the base  would make a delicious soup.  and it does! \\r\\nuse plenty of fresh mushrooms.  i buy them when they are marked 1/2 price at the grocery, as this is a good way to use your 'shrooms that are starting to get dark.  it is the soy sauce that transforms the broth from ho-hum to yum.  i try to use low sodium or home-made no sodium chicken broth so that i can use the soy for the sodium.  there is no sense of \"asian\" in this soup at all.  ( i would not make this without the soy. )  just a little bit adds the depth of flavor and even color...   \n",
              "6779   i wrote this because there are an astounding lack of chocolate tea recipes on the internet. \\r\\n\\r\\n the first time i heard about chocolate tea was doing a web search on chocolate. there seem to be a few companies out there who sell chocolate tea. i like to stay up late and had run out of coffee. i was in real need for a good tasting caffene beverage. i first thought chocolate tea would be yucky. we are conditioned to accept chocolate with coffee as a rule but not tea. i was very mistaken! \\r\\n\\r\\n tea and chocolate goes very well with each other and it is also very good for your body. both tea and chocolate are loaded with antioxidents. you may however not want to give this to small children because of the caffene. \\r\\n\\r\\n not having a recipe to follow, i created one. (this one) i used these ingredients because i had them on hand and it was quick...   \n",
              "16296  the first time i made this cake i grated a million pounds of carrots on a knucklebuster.  then they invented cuisinarts!  now it is much faster to shred the carrots on a fine shredding disk and no bloody knuckles!  i have baked it in 8\", 9\", 9x13\" pans so if you want to experiment with pan size it works.  one thing i found was baking and stacking the three layers is tricky.  my favorite way is two 8\" pans for a nice layer cake and an 8\" square pan to put into the freezer for unexpected company. i hope you try this wonderful cake.  update:  in the spirit of carrot cake stories, this cake was invented by a bunny named foo-foo.  he is very famous and even has a hit song which goes like this: sing to the tune of 'down by the station'..........     \\r\\n\\r\\n\\r\\n little bunny foo foo,\\r\\nhopping through the forest,\\r\\nscooping up the field mice,\\r\\nand bo...   \n",
              "\n",
              "       n_ingredients  sentence_count  \n",
              "18408            NaN              76  \n",
              "481              9.0              27  \n",
              "22566           10.0              24  \n",
              "6779             NaN              23  \n",
              "16296            NaN              23  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cda0c1d-be48-4ae3-b970-b3f80b95434e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>description</th>\n",
              "      <th>n_ingredients</th>\n",
              "      <th>sentence_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18408</th>\n",
              "      <td>my favorite buttercream icing for decorating</td>\n",
              "      <td>334113</td>\n",
              "      <td>30</td>\n",
              "      <td>681465</td>\n",
              "      <td>2008-10-30</td>\n",
              "      <td>12.0</td>\n",
              "      <td>this wonderful icing is used for icing cakes and cookies as well as for borders and art work on cakes.  it makes a delicious filling also between the layers of cakes and under fondant icing.  you can make roses but it takes 3 or more days to dry them depending on the humidity. \\r\\n\\r\\nthere are many versions of “buttercream” icing. some are made with eggs and all butter.  some varieties, you have to cook your sugar to a softball stage.  others are 100% shortening or a combination of shortening and butter.\\r\\n\\r\\neach decorator has his or her favorite.  i personally think that the best taste and textured recipe is the one that has you cook your sugar, add to whipped eggs and use pounds of butter per batch. but…. i live in a state that can easily be a 100 degrees for days on end during the summer and you know what butter does on hot days.  it melts! ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>alligator claws  avocado fritters  with chipotle lime dip</td>\n",
              "      <td>287008</td>\n",
              "      <td>45</td>\n",
              "      <td>765354</td>\n",
              "      <td>2008-02-19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>a translucent golden-brown crust allows the green of the avocado to be seen.  the crispy exterior is a counterpoint to the unctuous interior.  these are a signature dish for me, and the one i most often get requests to make (although my seafood and ricotta stuffed buckwheat pancakes run a close second).\\r\\n\\r\\nthese fritters came about ten years ago when i was shopping for a dinner i was making for a friend who is a cia-trained chef.  i was in a vegetable market and saw these gorgeous avocados that i just knew would be ripe in the next two days.  i tried to think of what i could do with them since a) everyone serves cold avocado, and b) i really am not fond of guacamole.  as i tried to think of what i could make with them that was hot, the work 'fritters' jumped into my head.  having never made a fritter before, i was a little surprised to have tha...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22566</th>\n",
              "      <td>rich barley mushroom soup</td>\n",
              "      <td>328708</td>\n",
              "      <td>60</td>\n",
              "      <td>221776</td>\n",
              "      <td>2008-10-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this is one of the best soups i've ever made and it is even worthy of company.  so simple, yet rich in deep, mushroomy flavor.  the inspiration was zaar #26877, a delicious mushroom rice casserole.  i found i couldn't stop eating the liquid before putting the casserole into the oven and that gave me the idea that the base  would make a delicious soup.  and it does! \\r\\nuse plenty of fresh mushrooms.  i buy them when they are marked 1/2 price at the grocery, as this is a good way to use your 'shrooms that are starting to get dark.  it is the soy sauce that transforms the broth from ho-hum to yum.  i try to use low sodium or home-made no sodium chicken broth so that i can use the soy for the sodium.  there is no sense of \"asian\" in this soup at all.  ( i would not make this without the soy. )  just a little bit adds the depth of flavor and even color...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6779</th>\n",
              "      <td>chocolate tea</td>\n",
              "      <td>205348</td>\n",
              "      <td>6</td>\n",
              "      <td>428824</td>\n",
              "      <td>2007-01-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i wrote this because there are an astounding lack of chocolate tea recipes on the internet. \\r\\n\\r\\n the first time i heard about chocolate tea was doing a web search on chocolate. there seem to be a few companies out there who sell chocolate tea. i like to stay up late and had run out of coffee. i was in real need for a good tasting caffene beverage. i first thought chocolate tea would be yucky. we are conditioned to accept chocolate with coffee as a rule but not tea. i was very mistaken! \\r\\n\\r\\n tea and chocolate goes very well with each other and it is also very good for your body. both tea and chocolate are loaded with antioxidents. you may however not want to give this to small children because of the caffene. \\r\\n\\r\\n not having a recipe to follow, i created one. (this one) i used these ingredients because i had them on hand and it was quick...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16296</th>\n",
              "      <td>little bunny foo foo cake  carrot cake  with cream cheese frosti</td>\n",
              "      <td>316000</td>\n",
              "      <td>68</td>\n",
              "      <td>689540</td>\n",
              "      <td>2008-07-27</td>\n",
              "      <td>14.0</td>\n",
              "      <td>the first time i made this cake i grated a million pounds of carrots on a knucklebuster.  then they invented cuisinarts!  now it is much faster to shred the carrots on a fine shredding disk and no bloody knuckles!  i have baked it in 8\", 9\", 9x13\" pans so if you want to experiment with pan size it works.  one thing i found was baking and stacking the three layers is tricky.  my favorite way is two 8\" pans for a nice layer cake and an 8\" square pan to put into the freezer for unexpected company. i hope you try this wonderful cake.  update:  in the spirit of carrot cake stories, this cake was invented by a bunny named foo-foo.  he is very famous and even has a hit song which goes like this: sing to the tune of 'down by the station'..........     \\r\\n\\r\\n\\r\\n little bunny foo foo,\\r\\nhopping through the forest,\\r\\nscooping up the field mice,\\r\\nand bo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cda0c1d-be48-4ae3-b970-b3f80b95434e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cda0c1d-be48-4ae3-b970-b3f80b95434e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cda0c1d-be48-4ae3-b970-b3f80b95434e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiKIKimTUs5a"
      },
      "source": [
        "8\\. Напишите функцию, которая для заданного предложения выводит информацию о частях речи слов, входящих в предложение, в следующем виде:\n",
        "```\n",
        "PRP   VBD   DT      NNS     CC   VBD      NNS        RB   \n",
        " I  omitted the raspberries and added strawberries instead\n",
        "``` \n",
        "Для определения части речи слова можно воспользоваться `nltk.pos_tag`.\n",
        "\n",
        "Проверьте работоспособность функции на названии рецепта с id 241106.\n",
        "\n",
        "Обратите внимание, что часть речи должна находиться ровно посередине над соотвествующим словом, а между самими словами должен быть ровно один пробел.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "def tag(sentence: str) -> str:\n",
        "  tokenizer = word_tokenize(sentence)\n",
        "  tagged_list = pos_tag(tokenizer)\n",
        "\n",
        "  res_word = ''\n",
        "  res_tag = ''\n",
        "\n",
        "  for elem in tagged_list:\n",
        "    word, tag = elem[0], elem[1]\n",
        "    n_spaces = abs(len(word) - len(tag))\n",
        "    if len(word) >= len(tag):\n",
        "      tag = ' ' * (n_spaces//2) + tag + ' ' * (n_spaces - n_spaces//2)\n",
        "    else:\n",
        "      word = ' ' * (n_spaces//2) + tag + ' ' * (n_spaces - n_spaces//2)\n",
        "      \n",
        "    res_tag += tag + ' '\n",
        "    res_word += word + ' '\n",
        "\n",
        "  return '\\n'.join([res_tag, res_word])\n",
        "\n",
        "\n",
        "sentence = df[df['id'] == 241106]['name'].tolist()[0]\n",
        "print(tag(sentence))"
      ],
      "metadata": {
        "id": "juxVWC6pVo8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf15533-4d7d-4040-e1c8-3fe320568564"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   JJ     NNS    IN     NNS    VBP    JJ   CC   JJ    NNS   \n",
            "eggplant steaks with chickpeas feta cheese and black olives \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}